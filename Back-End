import tkinter as tk
from tkinter import filedialog, messagebox
import pyaudio
import wave
import pygame
from google.cloud import speech_v1p1beta1 as speech
from google.cloud import translate_v2 as translate
from transformers import BartForConditionalGeneration, BartTokenizer
import spacy
from spacy.matcher import Matcher
import threading

recording = False
audio_path = "output.wav"

pygame.mixer.init()

BART_MODEL_NAME = "facebook/bart-large-cnn"
bart_model = BartForConditionalGeneration.from_pretrained(BART_MODEL_NAME)
bart_tokenizer = BartTokenizer.from_pretrained(BART_MODEL_NAME)

nlp = spacy.load("en_core_web_sm")

def transcribe_audio(audio_path, encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16, sample_rate=44100, language="en-US"):
    client = speech.SpeechClient()
    with open(audio_path, 'rb') as audio_file:
        content = audio_file.read()
        
    audio = speech.RecognitionAudio(content=content)
    config = speech.RecognitionConfig(
        encoding=encoding,
        sample_rate_hertz=sample_rate,
        language_code=language,
        use_enhanced=True,
        model='phone_call'
    )
    response = client.recognize(config=config, audio=audio)
    transcript = ""
    for result in response.results:
        transcript += result.alternatives[0].transcript
    return transcript


def summarize_text(text):
    inputs = bart_tokenizer([text], max_length=1024, return_tensors="pt", truncation=True)
    summary_ids = bart_model.generate(inputs["input_ids"], num_beams=4, min_length=30, max_length=500, early_stopping=True)
    summary = bart_tokenizer.decode(summary_ids[0], skip_special_tokens=True)
    return summary

def extract_appointments(text):
    doc = nlp(text)
    reminders = []
    
    # Define patterns for matching
    appointment_pattern = [{"LOWER": {"IN": ["appointment", "schedule", "meeting"]}},
                           {"IS_PUNCT": True, "OP": "?"},
                           {"ENT_TYPE": "DATE", "OP": "+"},
                           {"LOWER": "at", "OP": "?"},
                           {"ENT_TYPE": "TIME", "OP": "?"}]
    
    matcher = Matcher(nlp.vocab)
    matcher.add("APPOINTMENT_PATTERN", [appointment_pattern])
    
    matches = matcher(doc)
    
    for match_id, start, end in matches:
        span = doc[start:end]
        if "appointment" in span.text.lower():
            label = "Appointment"
        else:
            label = "Meeting"
        
        date_entity = [ent for ent in span.ents if ent.label_ == "DATE"]
        time_entity = [ent for ent in span.ents if ent.label_ == "TIME"]
        
        if time_entity:
            reminders.append(f"{label}: {date_entity[0].text} at {time_entity[0].text} EST")
        else:
            reminders.append(f"{label}: {date_entity[0].text}")
    
    return reminders

def transcribe_and_translate(audio_path, target_language="en"):
    transcript = transcribe_audio(audio_path)
    translate_client = translate.Client()
    result = translate_client.translate(transcript, target_language=target_language)
    return result["translatedText"]

def start_recording_thread():
    global recording
    recording = True
    p = pyaudio.PyAudio()
    stream = p.open(format=pyaudio.paInt16, channels=1, rate=44100, input=True, frames_per_buffer=1024)
    frames = []

    while recording:
        data = stream.read(1024)
        frames.append(data)

    stream.stop_stream()
    stream.close()
    p.terminate()

    with wave.open(audio_path, 'wb') as wf:
        wf.setnchannels(1)
        wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))
        wf.setframerate(44100)
        wf.writeframes(b''.join(frames))

def start_recording():
    thread = threading.Thread(target=start_recording_thread)
    thread.start()

def stop_recording():
    global recording
    recording = False

def play_audio():
    pygame.mixer.init()
    if pygame.mixer.music.get_busy():
        pygame.mixer.music.stop()
    pygame.mixer.music.load(audio_path)
    pygame.mixer.music.play()

def display_transcript():
    transcript = transcribe_audio(audio_path)
    messagebox.showinfo("Transcript", transcript)

def display_summary():
    transcript = transcribe_audio(audio_path)
    summary = summarize_text(transcript)
    messagebox.showinfo("Summary", summary)

def display_reminders():
    transcript = transcribe_audio(audio_path)
    reminders = extract_appointments(transcript)
    messagebox.showinfo("Reminders", "\n".join(reminders))

def display_translation():
    translated_text = transcribe_and_translate(audio_path)
    messagebox.showinfo("Translated Transcript", translated_text)

def main():
    root = tk.Tk()
    root.title("Audio Processing App")

    start_button = tk.Button(root, text="Accept Call", command=start_recording)
    start_button.pack()

    stop_button = tk.Button(root, text="End Call", command=stop_recording)
    stop_button.pack()

    play_button = tk.Button(root, text="Play Audio", command=play_audio)
    play_button.pack()

    transcript_button = tk.Button(root, text="View Transcript", command=display_transcript)
    transcript_button.pack()

    summary_button = tk.Button(root, text="View Summary", command=display_summary)
    summary_button.pack()

    reminders_button = tk.Button(root, text="View Reminders", command=display_reminders)
    reminders_button.pack()

    languages = [("English", "en"), ("Spanish", "es"), ("French", "fr")]
    selected_language = tk.StringVar(root)
    selected_language.set("en")
    lang_dropdown = tk.OptionMenu(root, selected_language, *[lang[0] for lang in languages])
    lang_dropdown.pack()

    translate_button = tk.Button(root, text="Translate Transcript", command=display_translation)
    translate_button.pack()

    root.mainloop()

if __name__ == "__main__":
    main()
    